{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFa5VyVNPCJY"
   },
   "source": [
    "# Project: Image Classification using Pipeline dan Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Qg7V4zoPCJi"
   },
   "source": [
    "**Description:**\n",
    "\n",
    "Welcome to your new assignment! In this project, you will have the opportunity to apply the knowledge and skills you've learned in class. The task at hand is to create an image classification project that predicts a person's age based on their photograph. You will be utilizing the power of machine learning pipelines to streamline your workflow and effectively manage the different stages of this project, from data preprocessing to model training and evaluation.\n",
    "\n",
    "Remember, the goal of this assignment is not just to build a model that makes accurate predictions, but also to understand the process of developing a machine-learning pipeline and the role each component plays in this process.\n",
    "\n",
    "We encourage you to be creative, explore different strategies, and most importantly, have fun while learning. We can't wait to see the innovative solutions you come up with! Best of luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZysTKHbGioh8"
   },
   "source": [
    "## Student Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i8BlcSWzioi3",
    "ExecuteTime": {
     "end_time": "2024-02-05T05:21:04.383616700Z",
     "start_time": "2024-02-05T05:21:04.374573700Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title #### Student Identity\n",
    "student_id = \"REA3X5EN\"  # @param {type:\"string\"}\n",
    "name = \"Steven Adi Santoso\"  # @param {type:\"string\"}\n",
    "drive_link = \"https://drive.google.com/drive/folders/1Z-I67iZtsgqSStCwrO58p7u39NxxhKQp?usp=sharing\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJWjH2kGV49k"
   },
   "source": [
    "## Installation and Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8wWESOr0PCJk",
    "ExecuteTime": {
     "end_time": "2024-02-05T05:21:19.737783500Z",
     "start_time": "2024-02-05T05:21:14.569843800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install rggrader\n",
    "from rggrader import submit, submit_image\n",
    "\n",
    "# Put your code here:\n",
    "!pip install gradio\n",
    "!pip install huggingface\n",
    "!pip install huggingface-hub\n",
    "!pip install transformers\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "import gradio as gr\n",
    "# ---- End of your code ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_mbLFq9Vvcg"
   },
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Io4CCbvZ-220"
   },
   "source": [
    "**Task 1: Image Classification using Hugging Face's Model**\n",
    "\n",
    "In this first task, your task is to develop an image classification pipeline that takes **an image URL as input**, displays the image, and uses the Hugging Face's model to predict the age of the person in the image. You can get the model [here](https://huggingface.co/nateraw/vit-age-classifier).\n",
    "\n",
    "Here are the key steps that you might be able to follow:\n",
    "\n",
    "1. **Image URL Input:** Your program should accept an image URL as input. Make sure to handle potential issues with invalid URLs or inaccessible images.\n",
    "2. **Image Display:** Display the image from the URL in your notebook. This will provide a visual confirmation that the correct image is being processed.\n",
    "3. **Model Loading and Prediction:** Load the 'nateraw/vit-age-classifier' model from Hugging Face's model hub and pass the image URL to the model to obtain the prediction. The model should predict the age of the person in the image.\n",
    "4. **Output Display:** Display the output from the model in a clear and understandable manner.\n",
    "\n",
    "## Submission\n",
    "\n",
    "- What percentage is the person in this picture (https://images.unsplash.com/photo-1596392927852-2a18c336fb78?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1280&q=80) is between age of \"3-9\"?\n",
    "\n",
    "Submit in the numeric format up to 5 digits behind the decimal point. For example in below output:\n",
    "\n",
    "```\n",
    "{'0-2': '0.00152',\n",
    " '3-9': '0.00105',\n",
    " '10-19': '0.02567',\n",
    " '20-29': '3.32545',\n",
    " '30-39': '51.75200',\n",
    " '40-49': '40.24234',\n",
    " '50-59': '4.47803',\n",
    " '60-69': '0.17092',\n",
    " 'more than 70': '0.00304'}\n",
    "```\n",
    "\n",
    "The answer would be `0.00105`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "H5LA1LcdPCJm",
    "ExecuteTime": {
     "end_time": "2024-02-05T05:21:25.199517400Z",
     "start_time": "2024-02-05T05:21:19.738588900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rusty\\Projects\\skill-academy-ml\\venv\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# @title #### 01. Image Classification using Hugging Face's Model\n",
    "\n",
    "# Put your code here:\n",
    "r = requests.get(\n",
    "    'https://images.unsplash.com/photo-1596392927852-2a18c336fb78?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1280&q=80')\n",
    "im = Image.open(BytesIO(r.content))\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained('nateraw/vit-age-classifier', cache_dir=r\"./checkpoint\")\n",
    "transforms = ViTFeatureExtractor.from_pretrained('nateraw/vit-age-classifier', cache_dir=r\"./checkpoint\")\n",
    "\n",
    "inputs = transforms(im, return_tensors='pt')\n",
    "output = model(**inputs)\n",
    "\n",
    "proba = output.logits.softmax(1)\n",
    "\n",
    "result = round(proba.tolist()[0][proba.argmax(1)], 5)\n",
    "\n",
    "# ---- End of your code ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "La_Uvs29-221",
    "ExecuteTime": {
     "end_time": "2024-02-05T05:21:25.806117100Z",
     "start_time": "2024-02-05T05:21:25.200518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Failed to submit assignment'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit Method\n",
    "assignment_id = \"00_pipeline_and_gradio\"\n",
    "question_id = \"01_image_classification_using_hugging_faces_model\"\n",
    "answer = result  # Put your answer here\n",
    "submit(student_id, name, assignment_id, answer, question_id, drive_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZBnPIJdVlYG"
   },
   "source": [
    "## Pipeline and Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2wOiPqDiojo"
   },
   "source": [
    "**Task 2: Image Classification using Hugging Face's Model and Gradio**\n",
    "\n",
    "In this second task, you will create a user-friendly interface using Gradio for your image classification pipeline that you created in Task 1. The difference with task 1 is, that in this task, you use **image files as input**, process them through the Hugging Face model, and display predictions output. The output displayed is **only the results with the highest `score`**.\n",
    "\n",
    "Here are the key steps that you might be able to follow:\n",
    "\n",
    "1. **Image Input:** Create a function to accept an image file as input. The image should be in a format that can be processed by the model.\n",
    "2. **Model Loading and Prediction:** Load the model from Hugging Face's model hub and pass the image to the model to obtain the prediction. The model predicts the age of the person in the image.\n",
    "3. **Gradio Interface:** Use Gradio to create a user-friendly interface for your application. The interface should allow users to upload an image file, and it should display the model's output in a clear and understandable manner.\n",
    "4. **Interface Launch:** Launch the Gradio interface. Make sure that the interface is accessible and easy to use.\n",
    "\n",
    "## Submisssion\n",
    "\n",
    "![Upload colab](https://storage.googleapis.com/rg-ai-bootcamp/project-3-pipeline-and-gradio/upload-colab.png)\n",
    "\n",
    "You need to submit screenshot of your Gradio's app. In Google Colab you can just use the \"Folder\" sidebar and click the upload button. Make sure your screenshot match below requirements:\n",
    "\n",
    "- You should upload a person's image to that app\n",
    "- The score should be included at the screenshot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fsMSIbrwTKuB",
    "ExecuteTime": {
     "end_time": "2024-02-05T05:23:47.431163800Z",
     "start_time": "2024-02-05T05:21:25.806117100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title #### 02. Image Classification using Hugging Face's Model and Gradio\n",
    "\n",
    "# Put your code here:\n",
    "def age_classifier(image):\n",
    "    im = Image.fromarray(image)\n",
    "\n",
    "    inputs = transforms(im, return_tensors='pt')\n",
    "    output = model(**inputs)\n",
    "\n",
    "    proba = output.logits.softmax(1)\n",
    "\n",
    "    age = [\n",
    "        '0-2',\n",
    "        '3-9',\n",
    "        '10-19',\n",
    "        '20-29',\n",
    "        '30-39',\n",
    "        '40-49',\n",
    "        '50-59',\n",
    "        '60-69',\n",
    "        'more than 70'\n",
    "    ]\n",
    "\n",
    "    ind = proba.argmax(1)\n",
    "\n",
    "    return {\n",
    "        'score': proba.tolist()[0][ind],\n",
    "        'label': age[ind]\n",
    "    }\n",
    "\n",
    "demo = gr.Interface(age_classifier, gr.Image(), \"json\")\n",
    "demo.launch(debug=True)\n",
    "\n",
    "# ---- End of your code ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iooYxZRr-222"
   },
   "source": [
    "Example of Expected Output:\n",
    "\n",
    "![gradio-result](https://storage.googleapis.com/rg-ai-bootcamp/project-3-pipeline-and-gradio/gradio-result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "c2tUQTyt-222",
    "ExecuteTime": {
     "end_time": "2024-02-05T05:24:01.027658Z",
     "start_time": "2024-02-05T05:23:51.708472500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Assignment successfully submitted'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit Method\n",
    "question_id = \"02_image_classification_using_hugging_faces_model_and_gradio\"\n",
    "submit_image(student_id, question_id, './Submission.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIYX1tCa-223"
   },
   "source": [
    "> Note: If your submission for Task-2 did not run (After you run it never changes from \"*\" to a number), stop the Code block that's running the Gradio app, then the submission will run. To stop the Code block, you can click on the Code block and then click the stop button."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
