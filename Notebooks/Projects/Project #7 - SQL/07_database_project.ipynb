{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def8e46c-7606-4991-9b29-9223ccacd54b",
   "metadata": {
    "id": "def8e46c-7606-4991-9b29-9223ccacd54b"
   },
   "source": [
    "# Project: Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a145c-7d01-4210-9699-0e1fef80ff19",
   "metadata": {
    "id": "911a145c-7d01-4210-9699-0e1fef80ff19"
   },
   "source": [
    "**Instructions for Students:**\n",
    "\n",
    "Please carefully follow these steps to complete and submit your project:\n",
    "\n",
    "1. **Completing the Project**: You are required to work on and complete all tasks in the provided project. Be disciplined and ensure that you thoroughly engage with each task.\n",
    "   \n",
    "2. **Creating a Google Drive Folder**: Each of you must create a new folder on your Google Drive if you haven't already. This will be the repository for all your completed assignment and project files, aiding you in keeping your work organized and accessible.\n",
    "   \n",
    "3. **Uploading Completed Project**: Upon completion of your project, make sure to upload all necessary files, involving codes, reports, and related documents into the created Google Drive folder. Save this link in the 'Student Identity' section and also provide it as the last parameter in the `submit` function that has been provided.\n",
    "   \n",
    "4. **Sharing Folder Link**: You're required to share the link to your project Google Drive folder. This is crucial for the submission and evaluation of your project.\n",
    "   \n",
    "5. **Setting Permission toPublic**: Please make sure your Google Drive folder is set to public. This allows your instructor to access your solutions and assess your work correctly.\n",
    "\n",
    "Adhering to these procedures will facilitate a smooth project evaluation process for you and the reviewers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018f21d-d661-4ae4-a50d-9fb66feb291d",
   "metadata": {
    "id": "8018f21d-d661-4ae4-a50d-9fb66feb291d"
   },
   "source": [
    "## Student Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc57472-0432-474a-b1f7-c825edfc007a",
   "metadata": {
    "id": "9fc57472-0432-474a-b1f7-c825edfc007a",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:51:55.626422Z",
     "start_time": "2024-02-13T09:51:52.989892Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rggrader in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: requests in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from rggrader) (2.31.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from rggrader) (2.2.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from rggrader) (10.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from pandas->rggrader) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from pandas->rggrader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from pandas->rggrader) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from pandas->rggrader) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from requests->rggrader) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from requests->rggrader) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from requests->rggrader) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from requests->rggrader) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rusty\\projects\\skill-academy-ml\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->rggrader) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# @title #### Student Identity\n",
    "student_id = \"REA3X5EN\"  # @param {type:\"string\"}\n",
    "name = \"Steven Adi Santoso\"  # @param {type:\"string\"}\n",
    "drive_link = \"https://drive.google.com/drive/folders/1_LqMlac_Etb2MH4YGWLMS5thicTQzW6R?usp=sharing\"  # @param {type:\"string\"}\n",
    "\n",
    "assignment_id = \"00_database_project\"\n",
    "\n",
    "# Import grader package\n",
    "!pip install rggrader\n",
    "from rggrader import submit, submit_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b9e0f7-75d2-476a-9b29-07c1a3800925",
   "metadata": {
    "id": "d3b9e0f7-75d2-476a-9b29-07c1a3800925"
   },
   "source": [
    "## Project Description\n",
    "\n",
    "In this project, you'll work with the Kaggle E-commerce dataset. Your tasks are to import this dataset into a SQLite database, explore it using SQL to identify key attributes and patterns, and perform basic data cleaning procedures. This project is designed to improve your skills in database management, SQL usage, and data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fea308-2c09-472c-a5ec-e4ba0900d496",
   "metadata": {
    "id": "84fea308-2c09-472c-a5ec-e4ba0900d496"
   },
   "source": [
    "Rmember to make a copy of this notebook in your Google Drive and work in your own copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b68327-fc7b-43de-9f16-b058d11d775b",
   "metadata": {
    "id": "e0b68327-fc7b-43de-9f16-b058d11d775b"
   },
   "source": [
    "## I. Loading and Querying with SQL\n",
    "\n",
    "In this task, you will use Kaggle E-commerce dataset. You need to download it from the link here: [Kaggle E-commerce data](https://www.kaggle.com/datasets/carrie1/ecommerce-data?select=data.csv).\n",
    "\n",
    "After you download the dataset, you will then import the dataset into SQL format, using SQLite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ecc459-5019-42d8-84a6-8644cecafef3",
   "metadata": {
    "id": "25ecc459-5019-42d8-84a6-8644cecafef3"
   },
   "source": [
    "### I.1. Package and Module Installation\n",
    "\n",
    "First, let's pool all package and module that you'll need in the installation section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62606ca1-5868-4c65-93ef-1d6ee8d8d59a",
   "metadata": {
    "id": "62606ca1-5868-4c65-93ef-1d6ee8d8d59a",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:51:58.219902100Z",
     "start_time": "2024-02-13T09:51:58.214951600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write any package/module installation that you need\n",
    "# pip install goes here, this helps declutter your output below\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0837717-de95-4193-9898-e2f4cadfcfc6",
   "metadata": {
    "id": "b0837717-de95-4193-9898-e2f4cadfcfc6"
   },
   "source": [
    "### I.2. Data Loading and SQL CREATE and INSERT to database table\n",
    "\n",
    "Now you can create the database and tables. Follow the same column naming as the dataset.\n",
    "\n",
    "Next insert all the data from the dataset into the table in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0e5e58-277e-41ef-9b1c-951e5d150191",
   "metadata": {
    "id": "3b0e5e58-277e-41ef-9b1c-951e5d150191",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:52:00.909097900Z",
     "start_time": "2024-02-13T09:51:59.299918600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your data loading to SQL database here\n",
    "\n",
    "# Connect to SQLite database in memory\n",
    "conn = sqlite3.connect('./database/invoices.db')\n",
    "\n",
    "# Create table and populate it using pandas\n",
    "df = pd.read_csv(r\"./database/raw.csv\", encoding='ISO-8859-1')\n",
    "df.to_sql('invoices', conn, if_exists='replace', index=False)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce0c59-0e94-480a-81ae-528e68356a15",
   "metadata": {
    "id": "30ce0c59-0e94-480a-81ae-528e68356a15"
   },
   "source": [
    "### I.3. Verifying the database\n",
    "\n",
    "Before we go to the next section, let's check our database first. You need to change the db_name and table_name with your database name and table name, afterwards you can just run the code block. The result should be:\n",
    "\n",
    "- Columns: ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']\n",
    "- Number of rows: 541909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa3c3f7-c6c5-4419-9b25-e8d7a8ec345a",
   "metadata": {
    "id": "1aa3c3f7-c6c5-4419-9b25-e8d7a8ec345a",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:52:00.948882Z",
     "start_time": "2024-02-13T09:52:00.911099800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']\n",
      "Number of rows: 541909\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect('./database/invoices.db')  #change db_name to your database name.\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Get column names\n",
    "cur.execute(\"PRAGMA table_info(invoices)\")  #change table_name to your table name\n",
    "sql_columns = [column[1] for column in\n",
    "               cur.fetchall()]  #the variable sql_columns is used for submission, do not change the variable name\n",
    "print(f\"Columns: {sql_columns}\")\n",
    "\n",
    "# Get total number of rows\n",
    "cur.execute(\"SELECT COUNT(*) FROM invoices\")  #change table_name to your table name\n",
    "sql_num_rows = cur.fetchone()[0]  #the variable sql_num_rows is used for submission, do not change the variable name\n",
    "print(f\"Number of rows: {sql_num_rows}\")\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b925f-fcf0-4518-81d8-598dba65d646",
   "metadata": {
    "id": "585b925f-fcf0-4518-81d8-598dba65d646"
   },
   "source": [
    "### I.3.4. Running SQL Queries\n",
    "\n",
    "Once we have the database in SQL format, let's do some data exploration and analysis.\n",
    "\n",
    "You are part of the engineering team at a global e-commerce company. Your company has a vast catalogue of products and serves customers around the globe. As the company continues to grow, the management decides it's time to expand the business even more.\n",
    "\n",
    "As an essential part of this expansion, your team is tasked with diving into your company's rich e-commerce dataset to extract crucial insights that will guide the expansion strategy.\n",
    "\n",
    "1. **Total number of unique products and unique customers:**\n",
    "\n",
    "   Your first task is to gauge the breadth of your operations. By determining the total number of unique products you sell and the total number of unique customers you serve, you can assess the scale and diversity of your business.\n",
    "\n",
    "2. **Total revenue for each product:**\n",
    "\n",
    "   Next, you're going to identify the star performers in your product portfolio. Calculating the total revenue for each product will reveal which items are the biggest revenue drivers. These insights can help guide decisions about product focus and marketing efforts. Limit the result to the top 5 product with the biggest revenue.\n",
    "\n",
    "3. **Most profitable countries (by total sales):**\n",
    "\n",
    "   To pinpoint the most fruitful geographic areas for your business, you'll identify which countries generate the most profit. This data will help you understand where your operations are already strong and where there might be potential for regional expansion. Limit the result to the top 5 countries with the biggest profit.\n",
    "\n",
    "4. **Top-selling products (by total sales) for each country from number 3:**\n",
    "\n",
    "   Product popularity may vary across different regions. Determining the top-selling products by sales for each country will provide a clear picture of regional preferences, informing decisions about product distribution in different markets. Limit the result to the top 5 products for each countries.\n",
    "\n",
    "4. **Top-selling products (by quantity) for each country from number 3:**\n",
    "\n",
    "   Product popularity may vary across different regions. Determining the top-selling products by quantity for each country will provide a clear picture of regional preferences, informing decisions about product distribution in different markets. Limit the result to the top 5 products for each countries.\n",
    "\n",
    "By answering these queries, your team will provide valuable data-driven insights that will directly contribute to the strategic decisions about where and how your business expands. As part of the engineering team, you're not just maintaining the technical infrastructure - you're shaping the future of the company.\n",
    "\n",
    "> Hint: The Product name is stored in column Descrioption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee33d9bc-2b35-4f78-b5d8-3eb65db1e361",
   "metadata": {
    "id": "ee33d9bc-2b35-4f78-b5d8-3eb65db1e361",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:52:03.010118900Z",
     "start_time": "2024-02-13T09:52:02.710780400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4070 4372\n"
     ]
    }
   ],
   "source": [
    "# Write your SQL Query here\n",
    "\n",
    "#use the following variable name to store the result from your SQL Query\n",
    "sql_num_products = 0\n",
    "sql_num_customers = 0\n",
    "sql_top_product_revenues = []  # list of tuples, where each tupple contains the product name and total revenue/total sales, see example\n",
    "sql_top_countries = []  # list of tuples, where each tupple contains the product name and total revenue/total sales, see example\n",
    "sql_top_selling_products_by_country_by_sales = {}  #dictionary where key is country name, value is a list of top-selling products by sales, see example below\n",
    "sql_top_selling_products_by_country_by_quantity = {}  #dictionary where key is country name, value is a list of top-selling products by quantity, see example below\n",
    "\n",
    "# 1. Find the total number of unique products and unique customers\n",
    "# Example: sql_num_products = 1559\n",
    "# Example: sql_num_customers = 1675\n",
    "\n",
    "# Connect to SQLite database in memory\n",
    "conn = sqlite3.connect('./database/invoices.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''\n",
    "    SELECT\n",
    "        (SELECT COUNT(DISTINCT StockCode) FROM invoices) AS total_products,\n",
    "        (SELECT COUNT(DISTINCT CustomerID) FROM invoices) AS total_customers\n",
    "''')\n",
    "\n",
    "result = cur.fetchone()\n",
    "\n",
    "sql_num_products = result[0]\n",
    "sql_num_customers = result[1]\n",
    "\n",
    "print(sql_num_products, sql_num_customers)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1cbbedc-d36e-4957-8359-98e948d5b177",
   "metadata": {
    "id": "d1cbbedc-d36e-4957-8359-98e948d5b177",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:52:06.013629300Z",
     "start_time": "2024-02-13T09:52:05.487047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('DOTCOM POSTAGE', 206245.48),\n",
      " ('REGENCY CAKESTAND 3 TIER', 164762.19),\n",
      " ('PARTY BUNTING', 98302.98),\n",
      " ('WHITE HANGING HEART T-LIGHT HOLDER', 97894.5),\n",
      " ('JUMBO BAG RED RETROSPOT', 92356.03)]\n"
     ]
    }
   ],
   "source": [
    "# 2. Calculate the total revenue for each product, limited to top 5\n",
    "# Example: sql_top_product_revenues = [('PRODUCT 1', 149385.12), ('PRODUCT 2', 54895.53), ('PRODUCT 3', 44545.55), ('PRODUCT 4', 38000.00), ('PRODUCT 5', 36000.00)]\n",
    "\n",
    "conn = sqlite3.connect('./database/invoices.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''\n",
    "    SELECT\n",
    "        Description,\n",
    "        SUM(UnitPrice * Quantity) as total_revenue\n",
    "    FROM\n",
    "        invoices\n",
    "    GROUP BY \n",
    "        StockCode\n",
    "    ORDER BY\n",
    "        total_revenue DESC\n",
    "''')\n",
    "\n",
    "sql_top_product_revenues = cur.fetchmany(5)\n",
    "\n",
    "pprint(sql_top_product_revenues)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af4cf62-9d0a-4cae-92cd-fac4a9468d5e",
   "metadata": {
    "id": "7af4cf62-9d0a-4cae-92cd-fac4a9468d5e",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:52:10.577606200Z",
     "start_time": "2024-02-13T09:52:10.329701700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('United Kingdom', 8187806.364),\n",
      " ('Netherlands', 284661.54),\n",
      " ('EIRE', 263276.82),\n",
      " ('Germany', 221698.21),\n",
      " ('France', 197403.9)]\n"
     ]
    }
   ],
   "source": [
    "# 3. Identify the most profitable countries (by total sales), limited to top 5\n",
    "# Example: sql_top_countries = [('COUNTRY 1', 600000.00), ('COUNTRY 2', 334857.45), ('COUNTRY 3', 245879.00), ('COUNTRY 4', 180000.00), ('COUNTRY 5', 164389.45)]\n",
    "\n",
    "conn = sqlite3.connect('./database/invoices.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''\n",
    "    SELECT\n",
    "        Country,\n",
    "        SUM(UnitPrice * Quantity) as total_revenue\n",
    "    FROM\n",
    "        invoices\n",
    "    GROUP BY \n",
    "        Country\n",
    "    ORDER BY\n",
    "        total_revenue DESC\n",
    "''')\n",
    "\n",
    "sql_top_countries = cur.fetchmany(5)\n",
    "\n",
    "pprint(sql_top_countries)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "776308cd-3733-4767-95c3-fc9d3eda3cb7",
   "metadata": {
    "id": "776308cd-3733-4767-95c3-fc9d3eda3cb7",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:52:13.969026500Z",
     "start_time": "2024-02-13T09:52:13.153078500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EIRE': [('REGENCY CAKESTAND 3 TIER', 7442.849999999999),\n",
      "          ('CARRIAGE', 5175.0),\n",
      "          ('JAM MAKING SET WITH JARS', 3089.0),\n",
      "          ('3 TIER CAKE TIN RED AND CREAM', 3041.55),\n",
      "          ('WHITE HANGING HEART T-LIGHT HOLDER', 2857.8)],\n",
      " 'France': [('POSTAGE', 15065.0),\n",
      "            ('RABBIT NIGHT LIGHT', 7275.12),\n",
      "            ('REGENCY CAKESTAND 3 TIER', 2581.7999999999997),\n",
      "            ('RED TOADSTOOL LED NIGHT LIGHT', 2168.1),\n",
      "            ('PLASTERS IN TIN WOODLAND ANIMALS', 1868.3999999999999)],\n",
      " 'Germany': [('POSTAGE', 20821.0),\n",
      "             ('REGENCY CAKESTAND 3 TIER', 8257.35),\n",
      "             ('ROUND SNACK BOXES SET OF4 WOODLAND ', 3554.7000000000003),\n",
      "             ('ROUND SNACK BOXES SET OF 4 FRUITS ', 1949.9500000000003),\n",
      "             ('SPACEBOY LUNCH BOX ', 1629.4499999999998)],\n",
      " 'Netherlands': [('RABBIT NIGHT LIGHT', 9568.48),\n",
      "                 ('ROUND SNACK BOXES SET OF4 WOODLAND ', 7991.4),\n",
      "                 ('SPACEBOY LUNCH BOX ', 7485.599999999999),\n",
      "                 ('DOLLY GIRL LUNCH BOX', 6828.599999999999),\n",
      "                 ('ROUND SNACK BOXES SET OF 4 FRUITS ', 4039.2)],\n",
      " 'United Kingdom': [('DOTCOM POSTAGE', 206245.48),\n",
      "                    ('REGENCY CAKESTAND 3 TIER', 134405.94),\n",
      "                    ('PARTY BUNTING', 92501.73),\n",
      "                    ('WHITE HANGING HEART T-LIGHT HOLDER', 92179.1),\n",
      "                    ('JUMBO BAG RED RETROSPOT', 84516.44)]}\n"
     ]
    }
   ],
   "source": [
    "# 4. Find the top-selling products (by total sales) for each country, limited to top 5\n",
    "# Example: sql_top_selling_products_by_country_by_sales = {\n",
    "#    'COUNTRY 1': [('COUNTRY 1 PRODUCT 1', 200000.00), ('COUNTRY 1 PRODUCT 2', 100000.00), ('COUNTRY 1 PRODUCT 3', 95348.00), ('COUNTRY 1 PRODUCT 4', 90000.43), ('COUNTRY 1 PRODUCT 5', 80000.00)],\n",
    "#    'COUNTRY 2': [('COUNTRY 2 PRODUCT 1', 9000.00), ('COUNTRY 2 PRODUCT 2', 7345.00), ('COUNTRY 2 PRODUCT 3', 6934.23), ('COUNTRY 2 PRODUCT 4', 6800.23), ('COUNTRY 2 PRODUCT 5', 4000.00)],\n",
    "#    ... to simplify, country 3 and 4 are not shown\n",
    "#    'COUNTRY 5': [('COUNTRY 5 PRODUCT 1', 7442.84), ('COUNTRY 5 PRODUCT 2', 5175.00), ('COUNTRY 5 PRODUCT 3', 3098.0), ('COUNTRY 5 PRODUCT 4', 3014.34), ('COUNTRY 5 PRODUCT 5', 2857.83)],\n",
    "\n",
    "conn = sqlite3.connect('./database/invoices.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''\n",
    "WITH top_5_product_in_country AS (\n",
    "    SELECT\n",
    "        Country,\n",
    "        Description,\n",
    "        SUM(UnitPrice * Quantity) as total_revenue,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY \n",
    "                Country \n",
    "            ORDER BY\n",
    "                SUM(UnitPrice * Quantity) DESC\n",
    "        ) AS row_num\n",
    "    FROM\n",
    "        invoices\n",
    "    GROUP BY\n",
    "        Country,\n",
    "        StockCode\n",
    "    )\n",
    "    SELECT\n",
    "        Country,\n",
    "        Description,\n",
    "        total_revenue\n",
    "    FROM \n",
    "        top_5_product_in_country\n",
    "    WHERE\n",
    "        row_num <= 5   \n",
    "''')\n",
    "\n",
    "sql_top_selling_products_by_country_by_sales = {key: [] for key, value in sql_top_countries}\n",
    "\n",
    "for country, code, value in cur.fetchall():\n",
    "    sql_top_selling_products_by_country_by_sales.get(country, []).append((code, value))\n",
    "\n",
    "pprint(sql_top_selling_products_by_country_by_sales)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54adc06d-fe7d-468c-8515-0b9f52170cf8",
   "metadata": {
    "id": "54adc06d-fe7d-468c-8515-0b9f52170cf8",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:52:18.776189900Z",
     "start_time": "2024-02-13T09:52:17.708200200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EIRE': [('PACK OF 72 RETROSPOT CAKE CASES', 1728),\n",
      "          ('60 TEATIME FAIRY CAKE CASES', 1536),\n",
      "          ('VINTAGE SNAP CARDS', 1492),\n",
      "          ('ASSORTED INCENSE PACK', 1440),\n",
      "          ('PACK OF 60 PINK PAISLEY CAKE CASES', 1296)],\n",
      " 'France': [('RABBIT NIGHT LIGHT', 4023),\n",
      "            ('MINI PAINT SET VINTAGE ', 2196),\n",
      "            ('RED TOADSTOOL LED NIGHT LIGHT', 1314),\n",
      "            ('SET/6 RED SPOTTY PAPER CUPS', 1272),\n",
      "            ('ASSORTED COLOUR BIRD ORNAMENT', 1204)],\n",
      " 'Germany': [('ROUND SNACK BOXES SET OF4 WOODLAND ', 1218),\n",
      "             ('ASSORTED COLOURS SILK FAN', 1164),\n",
      "             ('POSTAGE', 1104),\n",
      "             ('WOODLAND CHARLOTTE BAG', 1019),\n",
      "             ('PACK OF 72 RETROSPOT CAKE CASES', 1002)],\n",
      " 'Netherlands': [('RABBIT NIGHT LIGHT', 4801),\n",
      "                 ('SPACEBOY LUNCH BOX ', 4528),\n",
      "                 ('DOLLY GIRL LUNCH BOX', 4132),\n",
      "                 ('PACK OF 72 RETROSPOT CAKE CASES', 4128),\n",
      "                 ('ROUND SNACK BOXES SET OF4 WOODLAND ', 3132)],\n",
      " 'United Kingdom': [('WORLD WAR 2 GLIDERS ASSTD DESIGNS', 48326),\n",
      "                    ('JUMBO BAG RED RETROSPOT', 43167),\n",
      "                    ('POPCORN HOLDER', 34365),\n",
      "                    ('ASSORTED COLOUR BIRD ORNAMENT', 33679),\n",
      "                    ('WHITE HANGING HEART T-LIGHT HOLDER', 33193)]}\n"
     ]
    }
   ],
   "source": [
    "# 5. Find the top-selling products (by quantity) for each country, limited to top 5\n",
    "# Example: sql_top_selling_products_by_country_by_quantity = {\n",
    "#    'COUNTRY 1': [('COUNTRY 1 PRODUCT 1', 22343), ('COUNTRY 1 PRODUCT 2', 12345), ('COUNTRY 1 PRODUCT 3', 9534), ('COUNTRY 1 PRODUCT 4', 9000), ('COUNTRY 1 PRODUCT 5', 8000)],\n",
    "#    'COUNTRY 2': [('COUNTRY 2 PRODUCT 1', 9000), ('COUNTRY 2 PRODUCT 2', 7345), ('COUNTRY 2 PRODUCT 3', 6934), ('COUNTRY 2 PRODUCT 4', 6800), ('COUNTRY 2 PRODUCT 5', 4000)],\n",
    "#    ... to simplify, country 3 and 4 are not shown\n",
    "#    'COUNTRY 5': [('COUNTRY 5 PRODUCT 1', 48345), ('COUNTRY 5 PRODUCT 2', 43965), ('COUNTRY 5 PRODUCT 3', 43556), ('COUNTRY 5 PRODUCT 4', 34567), ('COUNTRY 5 PRODUCT 5', 33436)],\n",
    "\n",
    "conn = sqlite3.connect('./database/invoices.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''\n",
    "SELECT\n",
    "    Country,\n",
    "    SUM(Quantity) as total_quantity\n",
    "FROM\n",
    "    invoices\n",
    "GROUP BY\n",
    "    Country\n",
    "ORDER BY \n",
    "    total_quantity DESC\n",
    "''')\n",
    "\n",
    "sql_top_countries_by_quantity = cur.fetchmany(5)\n",
    "\n",
    "cur.execute('''\n",
    "WITH top_5_product_in_country AS (\n",
    "    SELECT\n",
    "        Country,\n",
    "        Description,\n",
    "        SUM(Quantity) as total_quantity,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY \n",
    "                Country \n",
    "            ORDER BY\n",
    "                SUM(Quantity) DESC\n",
    "        ) AS row_num\n",
    "    FROM\n",
    "        invoices\n",
    "    GROUP BY\n",
    "        Country,\n",
    "        Description\n",
    "    )\n",
    "    SELECT\n",
    "        Country,\n",
    "        Description,\n",
    "        total_quantity\n",
    "    FROM \n",
    "        top_5_product_in_country\n",
    "    WHERE\n",
    "        row_num <= 5   \n",
    "''')\n",
    "\n",
    "sql_top_selling_products_by_country_by_quantity = {key: [] for key, value in sql_top_countries_by_quantity}\n",
    "\n",
    "for country, code, value in cur.fetchall():\n",
    "    sql_top_selling_products_by_country_by_quantity.get(country, []).append((code, value))\n",
    "\n",
    "pprint(sql_top_selling_products_by_country_by_quantity)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d391ec9-ca95-4c56-b4f6-fccf8e0be14a",
   "metadata": {
    "id": "1d391ec9-ca95-4c56-b4f6-fccf8e0be14a"
   },
   "source": [
    "## II. Indexing and Querying with Elasticsearch\n",
    "\n",
    "You should have a better understanding of how to use SQL, now let's leverage the power of Elasticsearch to explore and analyze the data. We'll use the same dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd72e3-4d2f-4f3a-80ef-7b8b6440b124",
   "metadata": {
    "id": "e7dd72e3-4d2f-4f3a-80ef-7b8b6440b124"
   },
   "source": [
    "### II.1. Package and Module Installation\n",
    "\n",
    "First, let's pool all package and module that you'll need in the installation section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ca8f78-e33c-4552-9f4d-8bed711e661f",
   "metadata": {
    "id": "c8ca8f78-e33c-4552-9f4d-8bed711e661f",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:52:33.490555500Z",
     "start_time": "2024-02-13T09:52:33.354096600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write any package/module installation that you need\n",
    "# pip install goes here, this helps declutter your output below\n",
    "\n",
    "!pip install elasticsearch\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1633bd-61cb-4009-a064-b2ce2fdfeee4",
   "metadata": {
    "id": "6c1633bd-61cb-4009-a064-b2ce2fdfeee4"
   },
   "source": [
    "### II.2. Set up Elasticsearch Index\n",
    "\n",
    "The first step you need to do which is **preprocessing, let's keep it simple and simply drop all row that have missing values.**\n",
    "\n",
    "Next, you need to set up an Elasticsearch index. An Elasticsearch index is like a database in a traditional relational database. An index lets you store, search, and analyze big volumes of data quickly and in near real time.\n",
    "\n",
    "You'll also need to setup the mappings for the data types, let's do that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60d70360-3456-4e3c-b757-630bc129ad6d",
   "metadata": {
    "id": "60d70360-3456-4e3c-b757-630bc129ad6d",
    "ExecuteTime": {
     "end_time": "2024-02-13T09:52:38.713242600Z",
     "start_time": "2024-02-13T09:52:37.855987200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"acknowledged\": true,\n",
      "    \"shards_acknowledged\": true,\n",
      "    \"index\": \"invoices\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing here\n",
    "\n",
    "# Load your dataset and create an Elasticsearch index\n",
    "# Hints: use the BulkAPI for faster creation of the index\n",
    "\n",
    "# Create the connection\n",
    "es = Elasticsearch([{\n",
    "    'host': \"4.227.181.190\",  # I create my own VM using Azure and this IP will NOT be accessible later\n",
    "    'port': 9200,\n",
    "    'scheme': 'http'\n",
    "}])\n",
    "\n",
    "# Create the index\n",
    "response = es.options(ignore_status=[400]).indices.create(index='invoices')\n",
    "print(json.dumps(response.body, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Update the date mapping\n",
    "response = es.indices.put_mapping(index='invoices', body={\n",
    "    \"properties\": {\n",
    "        \"InvoiceDate\": {\n",
    "            \"type\": \"date\",\n",
    "            \"format\": \"M/d/yyyy H:m\"\n",
    "        },\n",
    "    }\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T09:52:41.422156Z",
     "start_time": "2024-02-13T09:52:41.097109800Z"
    }
   },
   "id": "572db8433c576835",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Populate the index\n",
    "# Function to create the body\n",
    "def generate_actions(csv_file):\n",
    "    # Reading the csv file\n",
    "    with open(csv_file, encoding='ISO-8859-1') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "\n",
    "        # Creating the body\n",
    "        for row in reader:\n",
    "            yield {\n",
    "                \"_index\": 'invoices',\n",
    "                \"_source\": row,\n",
    "            }\n",
    "\n",
    "helpers.bulk(es, generate_actions('./database/raw.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-13T09:52:53.302821500Z"
    }
   },
   "id": "e2e608f3c5e540e1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "39f7d0b8-698d-4666-a64a-8a1122bc5421",
   "metadata": {
    "id": "39f7d0b8-698d-4666-a64a-8a1122bc5421"
   },
   "source": [
    "### II.3. Verifying the index\n",
    "\n",
    "Before we go to the next section, let's check our index first. You need to change the my_index_name with your chosen index name, afterwards you can just run the code block. The result should be:\n",
    "\n",
    "- Columns: ['Country', 'CustomerID', 'Description', 'InvoiceDate', 'InvoiceNo', 'Quantity', 'StockCode', 'UnitPrice']\n",
    "- Number of rows: 406829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac844f06-2729-4299-a0c3-409a35fa39f1",
   "metadata": {
    "id": "ac844f06-2729-4299-a0c3-409a35fa39f1",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Connect to the Elasticsearch server\n",
    "es = Elasticsearch([{\n",
    "    'host': \"4.227.181.190\",  # I create my own VM using Azure and this IP will NOT be accessible later\n",
    "    'port': 9200,\n",
    "    'scheme': 'http'\n",
    "}])\n",
    "\n",
    "index_name = 'invoices'  #change the my_index_name value\n",
    "\n",
    "# Get index mapping (equivalent to getting column names in SQL)\n",
    "mapping = es.indices.get_mapping(index=index_name)\n",
    "es_columns = list(mapping[index_name]['mappings'][\n",
    "                      'properties'].keys())  #the variable es_columns is used for submission, do not change the variable name\n",
    "print(f\"Columns: {es_columns}\")\n",
    "\n",
    "# Count documents in the index (equivalent to counting rows in SQL)\n",
    "es_num_rows = es.count(index=index_name)[\n",
    "    'count']  #the variable es_num_rows is used for submission, do not change the variable name\n",
    "print(f\"Number of rows: {es_num_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3e34d-1092-4326-9f42-83fc2c3bfa29",
   "metadata": {
    "id": "dbf3e34d-1092-4326-9f42-83fc2c3bfa29"
   },
   "source": [
    "### II.4. Running Elasticsearch queries\n",
    "\n",
    "Once your e-commerce data is cleaned and ready, let's analyse the data to gain insights that will drive the expansion strategy, this time using Elasticsearch and we'll focus on one specific country, which is Germany.\n",
    "\n",
    "1. **Find all transactions for a specific country**\n",
    "\n",
    "   Your company operates globally, but you want to understand better how different countries contribute to your sales. By finding all transactions that happened in a specific country, you can get a clearer picture of your company's reach and performance in that location. In our case, we'll focus on the country Germany.\n",
    "\n",
    "\n",
    "2. **Find all unique products in Germany**\n",
    "\n",
    "   Your first task is to understand the breadth of your company's product portfolio in Germany. By determining the total number of unique products you sell, you can assess the scale and diversity of your operations.\n",
    "\n",
    "\n",
    "3. **Find the top 5 most purchased products in Germany**\n",
    "\n",
    "   Next up, you'll identify the best-selling products in your portfolio in Germany. Knowing which items are the most purchased can help guide decisions about product focus and marketing efforts. We'll limit the result to 5 most purchased products.\n",
    "\n",
    "\n",
    "By executing these tasks, you will enable your team to provide data-driven insights which will directly contribute to the strategic decisions about your business expansion. As part of the data engineering team, you're not only maintaining the technical infrastructure - you're shaping the future of the company.\n",
    "\n",
    "There are two more tasks below to check your understanding on how to handle date type data as well as searching using partial keyword:\n",
    "\n",
    "4. **Find a product's transactions over time**\n",
    "\n",
    "   Trends in purchases over time for specific products can provide insights into product popularity and seasonality. You decide to track a product's transactions over a period to understand its sales pattern. In this case we'll use the product \"I LOVE LONDON MINI RUCKSACK\"\n",
    "\n",
    "5. **Search for a product using a part of its description**\n",
    "\n",
    "   Finally, you want to investigate how robust and reliable your product search feature is. You decide to test it by searching for a product using a part of its description. In this case, we'll use the keyword \"PIN\". Return only unique product name. And the product names should be stored in a list in alphabetical order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38753049-8198-43fa-b497-b1b52e70e51e",
   "metadata": {
    "id": "38753049-8198-43fa-b497-b1b52e70e51e",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Write your Elasticsearch Query here\n",
    "\n",
    "#use the following variable name to store the result from your Elasticsearch Query\n",
    "es_total_unique_products = 0\n",
    "es_transactions_in_germany = 0\n",
    "es_top_products = {}  #dictionary where key is product name, value is the quantity sold, see example below\n",
    "es_transactions_over_time = {}  #dictionary where key is invoice date, value is the quantity sold, see example below\n",
    "es_unique_product_search = []  #list containing the products in alphabetical order\n",
    "\n",
    "# 1. Find all transactions for a specific country (Germany)\n",
    "# Example: es_transactions_in_germany = 7584\n",
    "result = es.count(\n",
    "    index='invoices',\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"Country\": \"Germany\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "es_transactions_in_germany = result['count']\n",
    "print(es_transactions_in_germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83c53f-bec9-484e-8f37-904879d987e3",
   "metadata": {
    "id": "ef83c53f-bec9-484e-8f37-904879d987e3",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# 2. Find all unique products in Germany\n",
    "# Hints: Use set() to remove duplicate values\n",
    "# Example: es_total_unique_products = 45345\n",
    "result = es.search(\n",
    "    index='invoices',\n",
    "    body={\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"Country\": \"Germany\"\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"unique_stock_code\": {\n",
    "                \"cardinality\": {\n",
    "                    \"field\": \"StockCode.keyword\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "es_total_unique_products = result['aggregations']['unique_stock_code']['value']\n",
    "print(es_total_unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c9f70-11de-4bd8-b4c2-9471392c0cf2",
   "metadata": {
    "id": "aa3c9f70-11de-4bd8-b4c2-9471392c0cf2",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# 3. Find the top 5 most purchased products in Germany\n",
    "# Example: es_top_products = {'PRODUCT 1': 498, 'PRODUCT 2': 452, 'PRODUCT 3': 342, 'PRODUCT 4': 231, 'PRODUCT 5': 123}\n",
    "\n",
    "result = es.search(\n",
    "    index='invoices',\n",
    "    body={\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"Country\": \"Germany\"\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"top_products\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"Description.keyword\",\n",
    "                    \"size\": 5,\n",
    "                    \"order\": {\"_count\": \"desc\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "es_top_products = {data['key']: data['doc_count'] for data in result['aggregations']['top_products']['buckets']}\n",
    "pprint(es_top_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa719a-c65c-47f7-b76e-c69674f3ade7",
   "metadata": {
    "id": "6baa719a-c65c-47f7-b76e-c69674f3ade7",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# 4. Find a product's transactions over time\n",
    "# Hints: Date format is M/d/yyyy H:m\n",
    "# Product = I LOVE LONDON MINI RUCKSACK\n",
    "# Example: es_transactions_over_time = {'12/12/2010 11:11': 1, 12/12/2010 11:12': 1}\n",
    "\n",
    "result = es.search(\n",
    "    index='invoices',\n",
    "    body={\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"Description\": \"I LOVE LONDON MINI RUCKSACK\"\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"transaction_history\": {\n",
    "                \"date_histogram\": {\n",
    "                    \"field\": \"InvoiceDate\",\n",
    "                    \"fixed_interval\": \"1d\",\n",
    "                    \"format\": \"M/d/yyyy H:m\",\n",
    "                    \"min_doc_count\": 0\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "es_transactions_over_time = {data['key_as_string']: data['doc_count'] for data in\n",
    "                             result['aggregations']['transaction_history']['buckets']}\n",
    "pprint(es_transactions_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6db11-734d-4638-a2d7-06ebe88a1db3",
   "metadata": {
    "id": "76d6db11-734d-4638-a2d7-06ebe88a1db3",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# 5. Search for a product using a part of its description\n",
    "# Hints: Return only unique Product names, see number 1\n",
    "# Example: es_unique_product_search = ['PRODUCT 1', 'PRODUCT 2']\n",
    "\n",
    "result = es.search(\n",
    "    index='invoices',\n",
    "    body={\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"Description\": \"PIN\"\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"unique_products\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"Description.keyword\",\n",
    "                    \"size\": 11\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "es_unique_product_search = [product['key'] for product in result['aggregations']['unique_products']['buckets']]\n",
    "pprint(es_unique_product_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d59af48-18c0-4e40-80ff-33a85030b205",
   "metadata": {
    "id": "5d59af48-18c0-4e40-80ff-33a85030b205"
   },
   "source": [
    "## Submission\n",
    "\n",
    "Once you are satisfied with the performance of your model, then you run the code block below to submit your project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d7f7f-711d-4f41-82a3-3c2562e59709",
   "metadata": {
    "id": "010d7f7f-711d-4f41-82a3-3c2562e59709",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Submit Method\n",
    "\n",
    "# Do not change the code below\n",
    "question_id = \"01_sql_columns\"\n",
    "submit(student_id, name, assignment_id, str(sql_columns), question_id, drive_link)\n",
    "question_id = \"02_sql_num_rows\"\n",
    "submit(student_id, name, assignment_id, str(sql_num_rows), question_id, drive_link)\n",
    "question_id = \"03_sql_num_products\"\n",
    "submit(student_id, name, assignment_id, str(sql_num_products), question_id, drive_link)\n",
    "question_id = \"04_sql_num_customers\"\n",
    "submit(student_id, name, assignment_id, str(sql_num_customers), question_id, drive_link)\n",
    "question_id = \"05_sql_top_product_revenues\"\n",
    "submit(student_id, name, assignment_id, str(sql_top_product_revenues), question_id, drive_link)\n",
    "question_id = \"06_sql_top_countries\"\n",
    "submit(student_id, name, assignment_id, str(sql_top_countries), question_id, drive_link)\n",
    "question_id = \"07_sql_top_selling_products_by_country_by_sales\"\n",
    "submit(student_id, name, assignment_id, str(sql_top_selling_products_by_country_by_sales), question_id, drive_link)\n",
    "question_id = \"08_sql_top_selling_products_by_country_by_quantity\"\n",
    "submit(student_id, name, assignment_id, str(sql_top_selling_products_by_country_by_quantity), question_id, drive_link)\n",
    "\n",
    "question_id = \"09_es_columns\"\n",
    "submit(student_id, name, assignment_id, str(es_columns), question_id, drive_link)\n",
    "question_id = \"10_es_num_rows\"\n",
    "submit(student_id, name, assignment_id, str(es_num_rows), question_id, drive_link)\n",
    "question_id = \"11_es_total_unique_products\"\n",
    "submit(student_id, name, assignment_id, str(es_total_unique_products), question_id, drive_link)\n",
    "question_id = \"12_es_transactions_in_germany\"\n",
    "submit(student_id, name, assignment_id, str(es_transactions_in_germany), question_id, drive_link)\n",
    "question_id = \"13_es_top_products\"\n",
    "submit(student_id, name, assignment_id, str(es_top_products), question_id, drive_link)\n",
    "question_id = \"14_es_transactions_over_time\"\n",
    "submit(student_id, name, assignment_id, str(es_transactions_over_time), question_id, drive_link)\n",
    "question_id = \"15_es_unique_product_search\"\n",
    "submit(student_id, name, assignment_id, str(es_unique_product_search), question_id, drive_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89b9ff-0d31-416a-b3c4-851c725fadf7",
   "metadata": {
    "id": "aa89b9ff-0d31-416a-b3c4-851c725fadf7"
   },
   "source": [
    "## FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
